{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e10ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ats_models.longmbart.longformer_enc_dec import MLongformerEncoderDecoderForConditionalGeneration,MLongformerEncoderDecoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57562620",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MLongformerEncoderDecoderConfig.from_pretrained(\"../../ats-models-custom-decoder/finetuned-mbart/baseline_fixed\")\n",
    "model = MLongformerEncoderDecoderForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "542be6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load(\"/home/joehms/repos/ats-models-custom-decoder/finetuned-mbart/baseline_fixed/epoch=33_rougeL=0.20040.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7456220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = checkpoint['state_dict']\n",
    "aligned_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    aligned_state_dict[key.replace(\"model.\",\"\",1)] = state_dict[key]\n",
    "aligned_state_dict['final_logits_bias'] = model.final_logits_bias\n",
    "model.load_state_dict(aligned_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4884f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = \"/home/joehms/repos/leichte-sprache-corpus/aligned/20min/test.src\"\n",
    "test_target = \"/home/joehms/repos/leichte-sprache-corpus/aligned/20min/test.trg\"\n",
    "\n",
    "val_source = \"/home/joehms/repos/leichte-sprache-corpus/aligned/20min/dev.src\"\n",
    "val_target = \"/home/joehms/repos/leichte-sprache-corpus/aligned/20min/dev.trg\"\n",
    "\n",
    "train_source = \"/home/joehms/repos/leichte-sprache-corpus/aligned/20min/train.src\"\n",
    "train_target = \"/home/joehms/repos/leichte-sprache-corpus/aligned/20min/train.trg\"\n",
    "\n",
    "tokenizer_path = \"../../ats-models-custom-decoder/modified-mbart\"\n",
    "max_input_length = 3072\n",
    "max_output_length = 1024\n",
    "beam_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b4ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartTokenizer\n",
    "\n",
    "tokenizer = MBartTokenizer.from_pretrained(tokenizer_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccaf7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ats_models.data import CustomDataset, CustomDatasetForInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95a33896",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustomDatasetForInference(src_file=test_source,\n",
    "                                     tgt_file=test_target,\n",
    "                                     name=\"test\",\n",
    "                                     tokenizer=tokenizer,\n",
    "                                     max_input_len=max_input_length,\n",
    "                                     max_output_len=max_output_length,\n",
    "                                     src_tags_included=True,\n",
    "                                     tgt_tags_included=True)\n",
    "\n",
    "train_set = CustomDataset(src_file=train_source,\n",
    "                          tgt_file=train_target,\n",
    "                          name=\"train\",\n",
    "                          tokenizer=tokenizer,\n",
    "                          max_input_len=max_input_length,\n",
    "                          max_output_len=max_output_length,\n",
    "                          src_tags_included=True,\n",
    "                          tgt_tags_included=True\n",
    "            )\n",
    "\n",
    "val_set = CustomDataset(src_file=val_source,\n",
    "                          tgt_file=val_target,\n",
    "                          name=\"train\",\n",
    "                          tokenizer=tokenizer,\n",
    "                          max_input_len=max_input_length,\n",
    "                          max_output_len=max_output_length,\n",
    "                          src_tags_included=True,\n",
    "                          tgt_tags_included=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b345c51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:36<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "#data_collator = CustomCollator(tokenizer=tokenizer, model=model, pad_to_multiple_of=8, padding=True)\n",
    "\n",
    "batch_size = 2\n",
    "data_loader =  iter(DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=CustomDataset.collate_fn(tokenizer)))\n",
    "\n",
    "counter = 0\n",
    "data = {}\n",
    "\n",
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "    \n",
    "for i in tqdm(range((int)(counter/batch_size), len(data_loader))):\n",
    "    inputs = next(data_loader)\n",
    "    input_ids, decoder_input_ids, labels = inputs['input_ids'], inputs['decoder_input_ids'], inputs['labels']\n",
    "    bsz, seqlen = decoder_input_ids.size()\n",
    "    input_ids, attention_mask = CustomDataset.prepare_input(input_ids, True, 'sliding_chunks', [512], tokenizer.pad_token_id, [-1])\n",
    "    decoder_attention_mask = (decoder_input_ids != tokenizer.pad_token_id)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "                input_ids.to(device),\n",
    "                attention_mask=attention_mask.to(device),\n",
    "                decoder_input_ids=decoder_input_ids.to(device),\n",
    "                decoder_attention_mask=decoder_attention_mask.to(device),\n",
    "                output_hidden_states=True,\n",
    "                return_dict=True,\n",
    "                output_attentions=True\n",
    "                )\n",
    "        logits = outputs['logits']\n",
    "        lprobs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "        ids = torch.argmax(lprobs, dim=2)\n",
    "        \n",
    "        ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction='none')\n",
    "        assert logits.shape[-1] == model.config.vocab_size\n",
    "        loss = ce_loss_fct(logits.view(-1, logits.shape[-1]), labels.view(-1).to(device)).view(ids.shape)\n",
    "        \n",
    "        \n",
    "        labels[labels == -100] = 1\n",
    "        for i in range(0, batch_size):            \n",
    "            data['loss_' + str(counter)] = loss[i].cpu().detach()\n",
    "            data['ids_' + str(counter)] = ids[i].cpu().detach()\n",
    "            counter += 1\n",
    "            \n",
    "np.savez_compressed('val_loss', **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8863c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3155869/1431439636.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mean_loss_per_token = summed_loss / count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loss_data = np.load('val_loss.npz')\n",
    "\n",
    "all_loss = []\n",
    "\n",
    "max_words = 0\n",
    "for key in loss_data.files:\n",
    "    if key.startswith(\"loss\"):\n",
    "        value = loss_data[key]\n",
    "        if value.shape[0] > max_words:\n",
    "            max_words = value.shape[0]\n",
    "\n",
    "for key in loss_data.files:\n",
    "    if key.startswith(\"loss\"):\n",
    "        \n",
    "        loss = np.expand_dims(loss_data[key],axis=0)\n",
    "        remainder = [0] *  int((max_words - len(loss[0,:])))\n",
    "        remainder = np.array([remainder] * len(loss[:,0]))\n",
    "        loss = np.concatenate((loss, remainder), axis=1)\n",
    "\n",
    "        all_loss.append(loss)\n",
    "\n",
    "loss_cat = np.concatenate(all_loss, axis=0)\n",
    "\n",
    "count = (loss_cat != 0).sum(axis=0)\n",
    "summed_loss = loss_cat.sum(axis=0)\n",
    "mean_loss_per_token = summed_loss / count\n",
    "mean_loss_per_token.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcaf615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "#plt.bar(count, height=10, width=0.8, bottom=None, align='center')\n",
    "\n",
    "#ax.bar(range(0,len(count)),count)\n",
    "#plt.show()\n",
    "\n",
    "ax.bar(range(0,len(count)),mean_loss_per_token)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c963ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
